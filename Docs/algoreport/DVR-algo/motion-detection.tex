%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Детектирование движения {\small\rm (\emph{А.Ахриев, А.Болтнев})}}%%%
\label{sec:motiondetect}                                       %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Для каждой точки кадра видеопоследовательности требуется определить,
есть ли в ней движение или нет.

\begin{enumerate}\advance\leftskip by -1em
%
\item Сначала производится понижения разрешения изображения в $k=1$ (разрешение не
понижается),$k=2$ или $k=4$ раза (переменная \textsf{DOWNSCALE}).
Это повышает производительность алгоритма и несколько снижает
уровень шума.
%
\item Далее происходит процедура выравнивания яркости. Для данной точки, сначала
вычисляется средние значения яркости $\overline y$ (канал Y) и
цветности $\overline u$, $\overline v$ (каналы U и V) по квадрату $d
\times d$ пикселов, а затем производится преобразование по формуле
\begin{eqnarray*}
  y &\leftarrow& {\textsf{g} \cdot (d^2 \cdot y     ) \over \overline y}\\
  u &\leftarrow& {\textsf{g} \cdot (d^2 \cdot u - \overline u) \over \overline y}\\
  v &\leftarrow& {\textsf{g} \cdot (d^2 \cdot v - \overline v) \over \overline y}
\end{eqnarray*}
Здесь  \textsf{g} -- константа, задающая диапазон значений в
полученном изображении. Данная процедура может быть реализована
очень эффективно.

Вычитание $d^2 \cdot u - \overline u$ и $d^2 \cdot v - \overline v$
связано с представлением цветного изображения в цветовом
пространстве Y, U и V.

\item Если текущий кадр -- первый в видеопоследовательности, то
устанавливаются начальные значения фона (текущим кадром) и порогов
(некоторым значением, сейчас это 5). Начальные значения порогов
влияют лишь конечное, достаточно непродолжительное время, поэтому
значение 5 подобрано экспериментально.

\item Далее в каждой точке для каждого канала Y, U, V вычисляется разность фона и текущего
кадра $\Delta$ (для каждого канала свой $\Delta$)и оценивается
движение. Конкретнее, если $\Delta > T_c/2$, точка помечается как
подозрительная, если $\Delta > T_c$, точка помечается как
движущаяся. \emph{Порог коррекции яркости} $T_c$ зависит от значения
яркости $\overline y$:

\[
{\overline y}^* = \frac{\overline y \, + \, 0.5 \cdot dim^2 \cdot
k}{dim^2 \cdot k },
\]

\[
T_c = C \cdot \,\mbox{f}( {\overline y}^* ),
\]

\[
\mbox{f}(x) = 1.3 + \frac{0.7 \cdot s^3}{x^3  + s^3},
\]

Здесь $4 < C < 6$, $s=128$. Чем меньше $C$, тем чувствительней алгоритм. Этот параметр может варьироваться извне алгоритма, через метод \verb"SetData()" класса \verb"CameraAnalyzer". Для этого используется класс \linebreak \verb"TAlgoSensitivity". Значение $0$ соответствует $C=6$, значение $1$ соответствует $C=4$. Диапазон изменения $C$ можно легко изменить.

 Такая зависимость учитывает, что после коррекции яркости в
областях с более низкой яркостью усиливаются шумы и помехи и в более
темных местах порог ставится выше.

\item Для каждой движущейся точки считается время в движении. Если
оно превышает некоторое значение \textsf{HOLE\_TIMEOUT} (задается в
параметрах), то точка считается дыркой, и пометка о движении
снимается, счетчик времени движения обнуляется.

\item Если точка $(x,y)$ не помечена как движущаяся, то в ней происходит обновление фона и значений порогов.
%
\begin{equation}
B(x,y) = \alpha \cdot B(x,y) + (1 - \alpha) \cdot F(x,y),
\end{equation}
%
где $B(x,y)$, $F(x,y)$ -- значения интенсивности в точке $(x,y)$ фона (\emph{background}) и текущего кадра (\emph{frame}) соответственно.

Значения порогов обновляются несколько хитрее, в зависимости от того, растет ли порог или уменьшается:
%
\[
\begin{array}{l}
\mbox{if} \,\,\, (d_{x,y} < T_{x,y}) \\
\qquad T_{x,y} = \alpha _{slow} \cdot T_{x,y} + (1 - \alpha _{slow}) \cdot d_{x,y} \\
\mbox{else} \\
\qquad T_{x,y} = \alpha \cdot T_{x,y} + (1 - \alpha) \cdot d_{x,y},
\end{array}
\]
%
причем значение порога ограничено снизу величиной девиации шума
%
\[ T_{x,y} = \min \left( T_{x,y}, \sigma _{noise} \right). \]
%
\noindent Здесь $\alpha _{slow} = 0.5 \alpha$, ($0 < \alpha < 1, \alpha$, сейчас $ \alpha=0.02$), $\sigma _{noise}$ является оценкой шума, считается как усредненная по всем не движущемся точкам разности значения пиксела на текущем и предыдущем кадре (Для каждого канала свое значение).

\item Далее по точкам движения строится прямоугольники движения, при
этом учитываются и подозрительные точки. Последовательно
перебираются точки движения. Для каждой из этих точек рекурсивно во
всех направлениях перебираются точки движения и подозрительные точки
на движение, во и все они помечаются как движущиеся. То есть
подозрительные точки помечаются как движущиеся, если касаются точек
нормального движения. Затем строятся описывающие прямоугольники
полученных областей и выдаются как рамки движения.


\end{enumerate}
